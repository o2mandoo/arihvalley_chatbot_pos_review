"""
ChatBI NL2SQL Agent - Vector DB ê¸°ë°˜ Dynamic Few-shot í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•œ NL2SQL ì‹œìŠ¤í…œ

ì•„í‚¤í…ì²˜:
1. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
2. ChromaDBì—ì„œ ìœ ì‚¬í•œ ì§ˆë¬¸-SQL ì˜ˆì‹œ ê²€ìƒ‰ (Semantic Search)
3. ê²€ìƒ‰ëœ ì˜ˆì‹œë¡œ Dynamic Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±
4. LLMì´ SQL ìƒì„±
5. PostgreSQLì—ì„œ SQL ì‹¤í–‰
6. ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜í•˜ì—¬ ì‘ë‹µ
"""

import os
import sys
import json
import pandas as pd
import re
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

# LangChain imports
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_community.utilities import SQLDatabase
try:
    from langchain_classic.chains import create_sql_query_chain
except ImportError:  # pragma: no cover - fallback for older installs
    from langchain.chains import create_sql_query_chain
from sqlalchemy import create_engine


@dataclass
class FewShotExample:
    """Few-shot ì˜ˆì‹œ ë°ì´í„° í´ë˜ìŠ¤"""
    question: str
    sql: str
    category: str


KOREAN_COLUMN_INFO = [
    ("ë ˆì½”ë“œID", "text", "ë ˆì½”ë“œ ê³ ìœ  ID"),
    ("ì£¼ë¬¸ë²ˆí˜¸", "text", "ì£¼ë¬¸ ë²ˆí˜¸"),
    ("ì£¼ë¬¸ì¼ì", "text", "ì£¼ë¬¸ ë‚ ì§œ (YYYY-MM-DD)"),
    ("ì£¼ë¬¸ì‹œê°„", "text", "ì£¼ë¬¸ ì‹œê°„ (HH:mm:ss)"),
    ("ì§€ì ëª…", "text", "ì§€ì ëª…"),
    ("ì§€ì—­ìœ í˜•", "text", "ì§€ì—­ ìœ í˜•"),
    ("ë©”ë‰´ëª…", "text", "ë©”ë‰´ëª…"),
    ("ì¹´í…Œê³ ë¦¬", "text", "ì¹´í…Œê³ ë¦¬"),
    ("ìˆ˜ëŸ‰", "int", "ì£¼ë¬¸ ìˆ˜ëŸ‰"),
    ("ë‹¨ê°€", "float", "ë‹¨ê°€"),
    ("ì‹¤íŒë§¤ê¸ˆì•¡", "float", "ì‹¤íŒë§¤ê¸ˆì•¡"),
    ("í• ì¸ê¸ˆì•¡", "float", "í• ì¸ ê¸ˆì•¡"),
    ("ê²°ì œìˆ˜ë‹¨", "text", "ê²°ì œ ìˆ˜ë‹¨"),
    ("ì£¼ë¬¸ì±„ë„", "text", "ì£¼ë¬¸ ì±„ë„"),
    ("ì£¼ë¬¸ìƒíƒœ", "text", "ì£¼ë¬¸ ìƒíƒœ"),
    ("ìƒì„±ì¼ì‹œ", "text", "ë ˆì½”ë“œ ìƒì„± ì‹œê°"),
    ("ìˆ˜ì •ì¼ì‹œ", "text", "ë ˆì½”ë“œ ìˆ˜ì • ì‹œê°"),
]


class VectorStoreManager:
    """ChromaDB ê¸°ë°˜ Vector Store ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, persist_directory: str = "./chroma_db"):
        self.persist_directory = persist_directory
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.vector_store = None

    def initialize_from_examples(self, examples: List[FewShotExample]) -> None:
        """Few-shot ì˜ˆì‹œë¡œ Vector Store ì´ˆê¸°í™”"""
        documents = []
        for i, example in enumerate(examples):
            # ì§ˆë¬¸ì„ Documentë¡œ ë³€í™˜, SQLì€ metadataì— ì €ì¥
            doc = Document(
                page_content=example.question,
                metadata={
                    "sql": example.sql,
                    "category": example.category,
                    "index": i
                }
            )
            documents.append(doc)

        # ChromaDBì— ì €ì¥
        self.vector_store = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory=self.persist_directory,
            collection_name="nl2sql_examples"
        )
        print(f"âœ… Vector Store ì´ˆê¸°í™” ì™„ë£Œ: {len(documents)}ê°œ ì˜ˆì‹œ ì €ì¥")

    def load_existing(self) -> bool:
        """ê¸°ì¡´ Vector Store ë¡œë“œ"""
        try:
            self.vector_store = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings,
                collection_name="nl2sql_examples"
            )
            count = self.vector_store._collection.count()
            if count > 0:
                print(f"âœ… ê¸°ì¡´ Vector Store ë¡œë“œ: {count}ê°œ ì˜ˆì‹œ")
                return True
            return False
        except Exception:
            return False

    def search_similar(self, query: str, k: int = 5) -> List[Dict]:
        """ìœ ì‚¬í•œ ì§ˆë¬¸-SQL í˜ì–´ ê²€ìƒ‰"""
        if not self.vector_store:
            raise ValueError("Vector Storeê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        results = self.vector_store.similarity_search_with_score(query, k=k)

        similar_examples = []
        for doc, score in results:
            similar_examples.append({
                "question": doc.page_content,
                "sql": doc.metadata["sql"],
                "category": doc.metadata["category"],
                "similarity_score": 1 - score  # distanceë¥¼ similarityë¡œ ë³€í™˜
            })

        return similar_examples


def load_env_from_shell_rc(var_name: str) -> Optional[str]:
    """zsh rc íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì°¾ê³ , ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ë°˜í™˜"""
    candidates = [
        os.path.expanduser("~/.zshrc"),
        os.path.expanduser("~/.zshenv"),
        os.path.expanduser("~/.zprofile"),
    ]

    pattern = re.compile(rf"^(export\s+)?{re.escape(var_name)}\s*=\s*(.+)$")

    for path in candidates:
        if not os.path.exists(path):
            continue
        try:
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    stripped = line.strip()
                    if not stripped or stripped.startswith("#"):
                        continue
                    match = pattern.match(stripped)
                    if not match:
                        continue
                    value = match.group(2).strip()
                    if (value.startswith("'") and value.endswith("'")) or (
                        value.startswith('"') and value.endswith('"')
                    ):
                        value = value[1:-1]
                    if value:
                        os.environ[var_name] = value
                        return value
        except OSError:
            continue

    return None


def normalize_sql(sql: str) -> str:
    """SQL ë¬¸ìì—´ ì •ì œ (ì½”ë“œë¸”ë¡/í”„ë¦¬í”½ìŠ¤ ì œê±°)"""
    sql = sql.strip()
    if "```" in sql:
        parts = sql.split("```")
        if len(parts) >= 2:
            sql = parts[1]
    if sql.startswith("```"):
        sql = sql.split("\n", 1)[1] if "\n" in sql else sql[3:]
    if sql.endswith("```"):
        sql = sql.rsplit("```", 1)[0]
    sql = sql.strip()
    if sql.lower().startswith("sql"):
        sql = sql.split("\n", 1)[1] if "\n" in sql else sql[3:]
        sql = sql.strip()

    upper = sql.upper()
    for prefix in ("SQLQUERY:", "SQL:"):
        if upper.startswith(prefix):
            sql = sql.split(":", 1)[1].strip()
            break
    return sql


class PostgresSQLExecutor:
    """PostgreSQL ê¸°ë°˜ SQL ì‹¤í–‰ê¸°"""

    def __init__(self, db_url: str, table_name: str = "sales_records"):
        self.db_url = db_url
        self.table_name = table_name
        self.engine = create_engine(db_url, pool_pre_ping=True)

    def load_dataframe(self, df: pd.DataFrame, table_name: str = "sales") -> None:
        raise NotImplementedError("PostgreSQL ëª¨ë“œì—ì„œëŠ” ì—‘ì…€ ë¡œë“œ ê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    def get_schema(self, table_name: Optional[str] = None) -> str:
        table = table_name or self.table_name
        schema_info = [f'  - "{name}" ({dtype})' for name, dtype, _ in KOREAN_COLUMN_INFO]
        return f"í…Œì´ë¸”ëª…: {table}\nì»¬ëŸ¼:\n" + "\n".join(schema_info)

    def get_sample_data(self, table_name: Optional[str] = None, limit: int = 3) -> str:
        table = table_name or self.table_name
        columns = ", ".join([f'"{name}"' for name, _, _ in KOREAN_COLUMN_INFO])
        df = pd.read_sql_query(f'SELECT {columns} FROM {table} LIMIT {limit}', self.engine)
        return df.to_string(index=False)

    def execute_sql(self, sql: str) -> Tuple[bool, any, str]:
        try:
            sql = normalize_sql(sql)
            df = pd.read_sql_query(sql, self.engine)
            return True, df, ""
        except Exception as e:
            return False, None, str(e)

    def close(self):
        if self.engine:
            self.engine.dispose()


class NL2SQLAgent:
    """NL2SQL ì—ì´ì „íŠ¸ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(
        self,
        model_name: Optional[str] = None,
        vector_store_path: str = "./chroma_db",
        num_examples: int = 5,
        db_url: Optional[str] = None,
        table_name: str = "sales_records",
        use_langchain_sql: bool = False,
        use_few_shot: bool = True
    ):
        self.num_examples = num_examples
        self.db_url = db_url
        self.table_name = table_name
        self.use_langchain_sql = use_langchain_sql
        self.use_few_shot = use_few_shot
        self.sql_dialect = "PostgreSQL"
        self.langchain_sql_chain = None
        self.sql_database = None

        # OpenAI API í‚¤ í™•ì¸
        if not os.environ.get("OPENAI_API_KEY"):
            load_env_from_shell_rc("OPENAI_API_KEY")
        if not os.environ.get("OPENAI_MODEL"):
            load_env_from_shell_rc("OPENAI_MODEL")

        self.model_name = model_name or os.environ.get("OPENAI_MODEL", "gpt-5-mini")

        if not os.environ.get("OPENAI_API_KEY"):
            raise EnvironmentError(
                "OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "export OPENAI_API_KEY='your-api-key'"
            )

        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(model=self.model_name, temperature=0)

        # Vector Store ì´ˆê¸°í™”
        self.vector_store_manager = VectorStoreManager(vector_store_path) if self.use_few_shot else None

        if not self.db_url:
            raise EnvironmentError(
                "DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "export DATABASE_URL='postgresql://user:pass@localhost:5433/dbname'"
            )

        # SQL ì‹¤í–‰ê¸°
        self.sql_executor = PostgresSQLExecutor(self.db_url, table_name=self.table_name)

        # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ (ë°ì´í„° ë¡œë“œ í›„ ì„¤ì •)
        self.table_schema = ""
        self.sample_data = ""
        self.last_sql: Optional[str] = None
        self.last_result_df: Optional[pd.DataFrame] = None
        self.last_mode: Optional[str] = None

        if self.db_url and self.use_langchain_sql:
            table_info = self._build_korean_table_info()
            try:
                self.sql_database = SQLDatabase.from_uri(
                    self.db_url,
                    include_tables=[self.table_name],
                    sample_rows_in_table_info=2,
                    custom_table_info={self.table_name: table_info},
                    view_support=True,
                )
            except TypeError:
                self.sql_database = SQLDatabase.from_uri(
                    self.db_url,
                    include_tables=[self.table_name],
                    sample_rows_in_table_info=2,
                    view_support=True,
                )
            self.langchain_sql_chain = create_sql_query_chain(self.llm, self.sql_database)

    def load_few_shot_examples(self, examples_path: str) -> None:
        """JSON íŒŒì¼ì—ì„œ Few-shot ì˜ˆì‹œ ë¡œë“œ"""
        if not self.use_few_shot or not self.vector_store_manager:
            return
        # ê¸°ì¡´ Vector Storeê°€ ìˆìœ¼ë©´ ë¡œë“œ
        if self.vector_store_manager.load_existing():
            return

        # ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        with open(examples_path, 'r', encoding='utf-8') as f:
            examples_data = json.load(f)

        examples = [
            FewShotExample(
                question=ex["question"],
                sql=ex["sql"],
                category=ex["category"]
            )
            for ex in examples_data
        ]

        self.vector_store_manager.initialize_from_examples(examples)

    def load_db_context(self) -> None:
        """PostgreSQLì—ì„œ ìŠ¤í‚¤ë§ˆ/ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ"""
        self.table_schema = self.sql_executor.get_schema(self.table_name)
        self.sample_data = self.sql_executor.get_sample_data(self.table_name)
        print(f"\nğŸ“Š ë°ì´í„° ì •ë³´:")
        print(self.table_schema)

    def _build_korean_table_info(self) -> str:
        """LangChain SQL ì²´ì¸ìš© í•œê¸€ ì»¬ëŸ¼ ìŠ¤í‚¤ë§ˆ ë¬¸ìì—´ ìƒì„±"""
        columns = ",\n  ".join([f'"{name}" {dtype}' for name, dtype, _ in KOREAN_COLUMN_INFO])
        return (
            "-- í•œê¸€ ì»¬ëŸ¼ëª…ì€ ë°˜ë“œì‹œ ìŒë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            f"CREATE TABLE {self.table_name} (\n  {columns}\n);"
        )

    def _build_prompt(self, question: str, similar_examples: List[Dict]) -> str:
        """Dynamic Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # Few-shot ì˜ˆì‹œ ë¬¸ìì—´ ìƒì„±
        examples_str = ""
        for i, ex in enumerate(similar_examples, 1):
            examples_str += f"""
ì˜ˆì‹œ {i}:
ì§ˆë¬¸: {ex['question']}
SQL: {ex['sql']}
"""

        rules = f"""1. PostgreSQL ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.
2. ë‚ ì§œ í•¨ìˆ˜ëŠ” CURRENT_DATE, DATE_TRUNC(), EXTRACT() ë“±ì„ ì‚¬ìš©í•˜ì„¸ìš”.
3. "ì£¼ë¬¸ì¼ì"ëŠ” í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ë‚ ì§œ ë¹„êµ ì‹œ TO_DATE("ì£¼ë¬¸ì¼ì", 'YYYY-MM-DD')ë¡œ ë³€í™˜í•˜ì„¸ìš”.
4. "ì£¼ë¬¸ ê±´ìˆ˜"ëŠ” COUNT(DISTINCT ("ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ì¼ì"))ë¡œ ì§‘ê³„í•˜ì„¸ìš”.
5. "ì‹œê°„ëŒ€ë³„"ì€ EXTRACT(HOUR FROM "ì£¼ë¬¸ì‹œê°„"::time)::intë¡œ ì§‘ê³„í•˜ì„¸ìš”.
6. í•œê¸€ ì»¬ëŸ¼ëª…ì€ ë°˜ë“œì‹œ ìŒë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ì‚¬ìš©í•˜ì„¸ìš”.
7. ë°˜ë“œì‹œ SQLë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ SQLë§Œ ì‘ì„±í•˜ì„¸ìš”.
8. í…Œì´ë¸”ëª…ì€ '{self.table_name}'ì…ë‹ˆë‹¤."""

        prompt = f"""ë‹¹ì‹ ì€ ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì™€ ìœ ì‚¬í•œ ì§ˆë¬¸-SQL ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ëŠ” SQLì„ ìƒì„±í•˜ì„¸ìš”.

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ
{self.table_schema}

## ìƒ˜í”Œ ë°ì´í„°
{self.sample_data}

## ìœ ì‚¬í•œ ì§ˆë¬¸-SQL ì˜ˆì‹œ (ì°¸ê³ ìš©)
{examples_str}

## ê·œì¹™
{rules}

## ì‚¬ìš©ì ì§ˆë¬¸
{question}

## SQL:
"""
        return prompt

    def _format_result(self, question: str, sql: str, result_df: pd.DataFrame) -> str:
        """ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ í¬ë§·íŒ…"""

        # ê²°ê³¼ ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        result_str = result_df.to_string(index=False) if len(result_df) <= 20 else result_df.head(20).to_string(index=False) + f"\n... (ì´ {len(result_df)}í–‰)"

        format_prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ ê²°ê³¼ì…ë‹ˆë‹¤.
ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ìˆ«ìëŠ” ì²œ ë‹¨ìœ„ êµ¬ë¶„ì(,)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

ì§ˆë¬¸: {question}

ì‹¤í–‰ëœ SQL:
{sql}

ì¿¼ë¦¬ ê²°ê³¼:
{result_str}

ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:"""

        response = self.llm.invoke(format_prompt)
        return response.content

    def _is_simple_question(self, question: str) -> bool:
        """ê°„ë‹¨ ì§ˆì˜ ì—¬ë¶€ íŒë‹¨ (LangChain SQL ìš°ì„  ì ìš©ìš©)"""
        complex_markers = [
            "ë¹„ìœ¨", "ì¶”ì´", "ì¦ê°", "ìƒê´€", "í†µê³„", "ë¹„êµ", "ì¡°í•©", "í”„ë¡œëª¨ì…˜",
            "ìƒìœ„", "í•˜ìœ„", "top", "rank", "ìœ ì˜ë¯¸", "ë¶„ì„", "ì—°ê´€"
        ]
        if any(marker in question.lower() for marker in complex_markers):
            return False
        return len(question) <= 60

    def _extract_sql_output(self, output: any) -> str:
        if isinstance(output, dict):
            for key in ("query", "sql", "result", "output"):
                if key in output:
                    return str(output[key])
            return json.dumps(output, ensure_ascii=False)
        return str(output)

    def _rewrite_date_filters(self, sql: str) -> str:
        if 'TO_DATE("ì£¼ë¬¸ì¼ì"' in sql:
            return sql
        pattern = r'"ì£¼ë¬¸ì¼ì"\s*(=|<>|!=|>=|<=|>|<|BETWEEN)\s*'
        return re.sub(
            pattern,
            r'TO_DATE("ì£¼ë¬¸ì¼ì", \'YYYY-MM-DD\') \1 ',
            sql,
            flags=re.IGNORECASE
        )

    def _rewrite_order_counts(self, sql: str) -> str:
        if 'DISTINCT ("ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ì¼ì")' in sql:
            return sql
        sql = re.sub(
            r'COUNT\s*\(\s*"ì£¼ë¬¸ë²ˆí˜¸"\s*\)',
            'COUNT(DISTINCT ("ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ì¼ì"))',
            sql,
            flags=re.IGNORECASE
        )
        sql = re.sub(
            r'COUNT\s*\(\s*\*\s*\)',
            'COUNT(DISTINCT ("ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ì¼ì"))',
            sql,
            flags=re.IGNORECASE
        )
        return sql

    def _rewrite_time_buckets(self, sql: str) -> str:
        if "EXTRACT(HOUR" in sql.upper():
            return sql
        sql = re.sub(
            r'SELECT\s+"ì£¼ë¬¸ì‹œê°„"\b',
            'SELECT EXTRACT(HOUR FROM "ì£¼ë¬¸ì‹œê°„"::time)::int as hour',
            sql,
            flags=re.IGNORECASE
        )
        return re.sub(
            r'"ì£¼ë¬¸ì‹œê°„"\b',
            'EXTRACT(HOUR FROM "ì£¼ë¬¸ì‹œê°„"::time)::int',
            sql,
            flags=re.IGNORECASE
        )

    def _post_process_sql(self, question: str, sql: str) -> str:
        fixed = normalize_sql(sql)
        fixed = self._rewrite_date_filters(fixed)

        order_markers = ["ì£¼ë¬¸ ê±´ìˆ˜", "ì£¼ë¬¸ê±´ìˆ˜", "ì£¼ë¬¸ ìˆ˜", "ì£¼ë¬¸ìˆ˜", "ì£¼ë¬¸ ê°œìˆ˜", "ì£¼ë¬¸ê°œìˆ˜", "ì£¼ë¬¸ê±´"]
        if any(marker in question for marker in order_markers):
            fixed = self._rewrite_order_counts(fixed)

        time_markers = ["ì‹œê°„ëŒ€", "ì‹œê°„ëŒ€ë³„", "ì‹œê°„ë³„", "ì‹œê°„ ë¶„í¬", "ì‹œê°„ëŒ€ ë¶„í¬"]
        if any(marker in question for marker in time_markers):
            fixed = self._rewrite_time_buckets(fixed)

        return fixed

    def _enhance_question_for_sql_chain(self, question: str) -> str:
        hints = []
        hints.append('ë‚ ì§œ ë¹„êµëŠ” TO_DATE("ì£¼ë¬¸ì¼ì", \'YYYY-MM-DD\')ë¡œ ë³€í™˜í•´ì„œ ë¹„êµí•˜ì„¸ìš”.')

        order_markers = ["ì£¼ë¬¸ ê±´ìˆ˜", "ì£¼ë¬¸ê±´ìˆ˜", "ì£¼ë¬¸ ìˆ˜", "ì£¼ë¬¸ìˆ˜", "ì£¼ë¬¸ ê°œìˆ˜", "ì£¼ë¬¸ê°œìˆ˜", "ì£¼ë¬¸ê±´"]
        if any(marker in question for marker in order_markers):
            hints.append('ì£¼ë¬¸ ê±´ìˆ˜ëŠ” COUNT(DISTINCT ("ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ì¼ì"))ë¡œ ì§‘ê³„í•˜ì„¸ìš”.')

        time_markers = ["ì‹œê°„ëŒ€", "ì‹œê°„ëŒ€ë³„", "ì‹œê°„ë³„", "ì‹œê°„ ë¶„í¬", "ì‹œê°„ëŒ€ ë¶„í¬"]
        if any(marker in question for marker in time_markers):
            hints.append('ì‹œê°„ëŒ€ë³„ ì§‘ê³„ëŠ” EXTRACT(HOUR FROM "ì£¼ë¬¸ì‹œê°„"::time)::int ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í•‘í•˜ì„¸ìš”.')

        if not hints:
            return question

        return question + "\n\nSQL ì‘ì„± íŒíŠ¸: " + " ".join(hints)

    def _generate_sql_langchain(self, question: str) -> str:
        if not self.langchain_sql_chain:
            raise ValueError("LangChain SQL ì²´ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        enhanced_question = self._enhance_question_for_sql_chain(question)
        try:
            output = self.langchain_sql_chain.invoke({"question": enhanced_question})
        except Exception:
            output = self.langchain_sql_chain.invoke({"input": enhanced_question})
        sql = self._extract_sql_output(output)
        return normalize_sql(sql)

    def _execute_with_retry(self, question: str, sql: str) -> Tuple[bool, Optional[pd.DataFrame], str, str]:
        sql = self._post_process_sql(question, sql)
        success, result_df, error = self.sql_executor.execute_sql(sql)
        if success:
            return True, result_df, sql, ""

        retry_prompt = f"""ì´ì „ SQL ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ì˜¤ë¥˜ ë©”ì‹œì§€: {error}

ì›ë˜ SQL:
{sql}

ìŠ¤í‚¤ë§ˆ:
{self.table_schema}

ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì˜¬ë°”ë¥¸ SQLì„ ì‘ì„±í•´ì£¼ì„¸ìš”. SQLë§Œ ì¶œë ¥í•˜ì„¸ìš”:"""

        retry_response = self.llm.invoke(retry_prompt)
        fixed_sql = retry_response.content.strip()
        fixed_sql = self._post_process_sql(question, fixed_sql)
        success, result_df, error = self.sql_executor.execute_sql(fixed_sql)
        if success:
            return True, result_df, fixed_sql, ""

        return False, None, fixed_sql, error

    def format_result_table(self, result_df: Optional[pd.DataFrame], limit: int = 20) -> str:
        """ê²°ê³¼ë¥¼ í„°ë¯¸ë„ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” í‘œ í˜•íƒœë¡œ ì¶œë ¥"""
        if result_df is None or result_df.empty:
            return ""
        preview_df = result_df.copy()

        columns_env = os.environ.get("CHATBI_PREVIEW_COLUMNS", "")
        if columns_env:
            columns = [col.strip() for col in columns_env.split(",") if col.strip()]
            existing = [col for col in columns if col in preview_df.columns]
            if existing:
                preview_df = preview_df[existing]

        sort_env = os.environ.get("CHATBI_PREVIEW_SORT", "").strip()
        if sort_env:
            sort_col = sort_env
            sort_order = "asc"
            if ":" in sort_env:
                sort_col, sort_order = [part.strip() for part in sort_env.split(":", 1)]
            elif " " in sort_env:
                parts = [part.strip() for part in sort_env.split(" ", 1)]
                sort_col = parts[0]
                if len(parts) > 1:
                    sort_order = parts[1]

            if sort_col in preview_df.columns:
                ascending = sort_order.lower() != "desc"
                preview_df = preview_df.sort_values(by=sort_col, ascending=ascending)

        limit_env = os.environ.get("CHATBI_PREVIEW_LIMIT", "").strip()
        preview_limit = limit
        if limit_env.isdigit():
            preview_limit = max(1, int(limit_env))

        if len(preview_df) <= preview_limit:
            return preview_df.to_string(index=False)
        head = preview_df.head(preview_limit).to_string(index=False)
        return f"{head}\n... (ì´ {len(preview_df)}í–‰)"

    def query(self, question: str) -> str:
        """ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬"""
        langchain_attempted = False

        if self.use_langchain_sql and self._is_simple_question(question):
            langchain_attempted = True
            self.last_mode = "langchain"
            print("\nğŸ¤– (LangChain SQL) ì‰¬ìš´ ì§ˆì˜ ì²˜ë¦¬ ì¤‘...")
            generated_sql = self._generate_sql_langchain(question)
            print(f"\nğŸ“ ìƒì„±ëœ SQL:\n{generated_sql}")

            print("\nâš™ï¸ SQL ì‹¤í–‰ ì¤‘...")
            success, result_df, final_sql, error = self._execute_with_retry(question, generated_sql)
            if success:
                self.last_sql = final_sql
                self.last_result_df = result_df
                print("\nğŸ“Š ê²°ê³¼ ë¶„ì„ ì¤‘...")
                return self._format_result(question, final_sql, result_df)
            print(f"âš ï¸ LangChain SQL ì‹¤í–‰ ì˜¤ë¥˜: {error}")

        if self.use_few_shot and self.vector_store_manager:
            self.last_mode = "few_shot"
            print("\nğŸ” ìœ ì‚¬í•œ ì˜ˆì‹œ ê²€ìƒ‰ ì¤‘...")
            similar_examples = self.vector_store_manager.search_similar(
                question,
                k=self.num_examples
            )

            print(f"   ê²€ìƒ‰ëœ ì˜ˆì‹œ {len(similar_examples)}ê°œ:")
            for i, ex in enumerate(similar_examples[:3], 1):
                print(f"   {i}. {ex['question'][:40]}... (ìœ ì‚¬ë„: {ex['similarity_score']:.3f})")

            print("\nğŸ¤– SQL ìƒì„± ì¤‘...")
            prompt = self._build_prompt(question, similar_examples)
            sql_response = self.llm.invoke(prompt)
            generated_sql = sql_response.content.strip()

            print(f"\nğŸ“ ìƒì„±ëœ SQL:\n{generated_sql}")
            print("\nâš™ï¸ SQL ì‹¤í–‰ ì¤‘...")
            success, result_df, final_sql, error = self._execute_with_retry(question, generated_sql)

            if success:
                self.last_sql = final_sql
                self.last_result_df = result_df
                print("\nğŸ“Š ê²°ê³¼ ë¶„ì„ ì¤‘...")
                return self._format_result(question, final_sql, result_df)

            print(f"âš ï¸ Few-shot SQL ì‹¤í–‰ ì˜¤ë¥˜: {error}")

        if self.use_langchain_sql and not langchain_attempted:
            self.last_mode = "langchain"
            print("\nğŸ¤– (LangChain SQL) í´ë°± ì‹¤í–‰ ì¤‘...")
            generated_sql = self._generate_sql_langchain(question)
            print(f"\nğŸ“ ìƒì„±ëœ SQL:\n{generated_sql}")

            print("\nâš™ï¸ SQL ì‹¤í–‰ ì¤‘...")
            success, result_df, final_sql, error = self._execute_with_retry(question, generated_sql)
            if success:
                self.last_sql = final_sql
                self.last_result_df = result_df
                print("\nğŸ“Š ê²°ê³¼ ë¶„ì„ ì¤‘...")
                return self._format_result(question, final_sql, result_df)
            self.last_sql = final_sql
            self.last_result_df = None
            return f"âŒ SQL ì‹¤í–‰ ì‹¤íŒ¨: {error}\n\nìƒì„±ëœ SQL:\n{final_sql}"

        return "âŒ SQL ìƒì„± ì „ëµì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.sql_executor.close()


def print_header():
    """í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("ğŸš€ ChatBI NL2SQL Agent (Postgres/LangChain ì§€ì›)")
    print("=" * 60)


def run_chat_loop(agent: NL2SQLAgent):
    """ëŒ€í™” ë£¨í”„ ì‹¤í–‰"""
    print("\nğŸ’¬ ChatBIê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ë§¤ì¶œ ë°ì´í„°ì— ëŒ€í•´ ìì—°ì–´ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
    print("-" * 60)
    print("ì˜ˆì‹œ ì§ˆë¬¸:")
    print("  â€¢ ì˜¤ëŠ˜ ì „ì²´ ì§€ì  ì´ ë§¤ì¶œ í•©ê³„ ì–¼ë§ˆì•¼?")
    print("  â€¢ ê°€ì¥ ë§ì´ íŒ”ë¦° ë©”ë‰´ Top 5 ì•Œë ¤ì¤˜")
    print("  â€¢ ì§€ì ë³„ ë§¤ì¶œì„ ë¹„êµí•´ì¤˜")
    print("-" * 60)
    print("(ì¢…ë£Œ: 'exit' ì…ë ¥)\n")

    while True:
        try:
            user_input = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: exit): ").strip()

            if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                print("\nğŸ‘‹ ChatBIë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break

            if not user_input:
                print("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
                continue

            # ì§ˆë¬¸ ì²˜ë¦¬
            answer = agent.query(user_input)

            print("\n" + "=" * 60)
            print("ğŸ“ ë‹µë³€:")
            print("=" * 60)
            print(answer)
            if agent.last_sql:
                print("\n" + "-" * 60)
                print("ğŸ” ì‹¤í–‰ëœ SQL:")
                print("-" * 60)
                print(agent.last_sql)
            result_table = agent.format_result_table(agent.last_result_df)
            if result_table:
                print("\n" + "-" * 60)
                print("ğŸ“‹ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:")
                print("-" * 60)
                print(result_table)
            print("=" * 60 + "\n")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ChatBIë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print("ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ê¸°ë³¸ ì„¤ì •
    EXAMPLES_FILE = "chatbi_nl2sql/few_shot_examples.json"
    EXAMPLES_FILE_PG = "chatbi_nl2sql/few_shot_examples_postgres_ko.json"
    VECTOR_STORE_PATH = "./chatbi_nl2sql/chroma_db"
    if not os.environ.get("OPENAI_MODEL"):
        load_env_from_shell_rc("OPENAI_MODEL")
    if not os.environ.get("DATABASE_URL"):
        load_env_from_shell_rc("DATABASE_URL")

    DATABASE_URL = os.environ.get("DATABASE_URL")
    MODEL_NAME = os.environ.get("OPENAI_MODEL", "gpt-5-mini")
    TABLE_NAME = os.environ.get("CHATBI_TABLE", "sales_records")
    USE_FEW_SHOT = os.environ.get("CHATBI_USE_FEW_SHOT", "0") == "1"

    print_header()
    if not DATABASE_URL:
        raise EnvironmentError(
            "DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "export DATABASE_URL='postgresql://user:pass@localhost:5433/dbname'"
        )

    print(f"ğŸ—„ï¸  DB: {DATABASE_URL}")
    print(f"ğŸ“‹ í…Œì´ë¸”: {TABLE_NAME}")
    print(f"ğŸ¤– ëª¨ë¸: {MODEL_NAME}")
    print(f"ğŸ“š Few-shot ì‚¬ìš©: {USE_FEW_SHOT}")

    try:
        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        print("\nğŸ”§ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        if DATABASE_URL and os.path.exists(EXAMPLES_FILE_PG):
            EXAMPLES_FILE = EXAMPLES_FILE_PG
            VECTOR_STORE_PATH = "./chatbi_nl2sql/chroma_db_pg_ko"

        agent = NL2SQLAgent(
            model_name=MODEL_NAME,
            vector_store_path=VECTOR_STORE_PATH,
            num_examples=5,
            db_url=DATABASE_URL,
            table_name=TABLE_NAME,
            use_langchain_sql=bool(DATABASE_URL),
            use_few_shot=USE_FEW_SHOT if DATABASE_URL else True
        )
        if USE_FEW_SHOT:
            print("\nğŸ“š Few-shot ì˜ˆì‹œ ë¡œë“œ ì¤‘...")
            agent.load_few_shot_examples(EXAMPLES_FILE)

        print("\nğŸ“‚ DB ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì¤‘...")
        agent.load_db_context()

        # ëŒ€í™” ë£¨í”„ ì‹¤í–‰
        run_chat_loop(agent)

        # ì •ë¦¬
        agent.close()

    except FileNotFoundError as e:
        print(f"\nâŒ {e}")
        sys.exit(1)
    except EnvironmentError as e:
        print(f"\nâŒ {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
