"""
ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë“ˆ - í†µê³„ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
"""
import pandas as pd
import json
from collections import Counter
from typing import Dict, List
import logging

logger = logging.getLogger(__name__)


class ReportGenerator:
    """ë¦¬í¬íŠ¸ ìƒì„± í´ë˜ìŠ¤"""

    def __init__(self, analyzed_df: pd.DataFrame):
        """
        Args:
            analyzed_df: LLM ë¶„ì„ì´ ì™„ë£Œëœ ë°ì´í„°í”„ë ˆì„
        """
        self.df = analyzed_df
        self.score_cols = ['ì‹œì„¤_ì ìˆ˜', 'ì„œë¹„ìŠ¤_ì ìˆ˜', 'ë§›_ì ìˆ˜']

        # ì´ì  ê³„ì‚°
        if 'ì´ì ' not in self.df.columns:
            self.df['ì´ì '] = self.df[self.score_cols].sum(axis=1)

    def get_basic_stats(self) -> Dict:
        """ê¸°ë³¸ í†µê³„ ì¶”ì¶œ"""
        stats = {
            'total_reviews': len(self.df),
            'avg_scores': {
                'ì‹œì„¤': self.df['ì‹œì„¤_ì ìˆ˜'].mean(),
                'ì„œë¹„ìŠ¤': self.df['ì„œë¹„ìŠ¤_ì ìˆ˜'].mean(),
                'ë§›': self.df['ë§›_ì ìˆ˜'].mean(),
                'ì´ì ': self.df['ì´ì '].mean()
            }
        }
        return stats

    def extract_keywords(self) -> Dict:
        """í‚¤ì›Œë“œ ì¶”ì¶œ (ê¸ì •/ë¶€ì •)"""
        all_positive = []
        all_negative = []

        for col in ['ì‹œì„¤_ê¸ì •í‚¤ì›Œë“œ', 'ì„œë¹„ìŠ¤_ê¸ì •í‚¤ì›Œë“œ', 'ë§›_ê¸ì •í‚¤ì›Œë“œ']:
            keywords = self.df[col].dropna().str.split(', ').sum()
            all_positive.extend([k.strip() for k in keywords if k.strip()])

        for col in ['ì‹œì„¤_ë¶€ì •í‚¤ì›Œë“œ', 'ì„œë¹„ìŠ¤_ë¶€ì •í‚¤ì›Œë“œ', 'ë§›_ë¶€ì •í‚¤ì›Œë“œ']:
            keywords = self.df[col].dropna().str.split(', ').sum()
            all_negative.extend([k.strip() for k in keywords if k.strip()])

        positive_counter = Counter(all_positive)
        negative_counter = Counter(all_negative)

        return {
            'positive': positive_counter.most_common(20),
            'negative': negative_counter.most_common(20)
        }

    def extract_customer_needs(self) -> List[tuple]:
        """ê³ ê° ë‹ˆì¦ˆ ì¶”ì¶œ"""
        needs = self.df['ê³ ê°ë‹ˆì¦ˆ'].dropna().str.split(',').sum()
        needs_clean = [n.strip() for n in needs if n.strip()]
        needs_counter = Counter(needs_clean)
        return needs_counter.most_common(15)

    def analyze_menus(self) -> pd.DataFrame:
        """ë©”ë‰´ ë¶„ì„"""
        menu_evaluations = []

        for idx, row in self.df.iterrows():
            menu_json = row['ë©”ë‰´í‰ê°€_JSON']
            if pd.notna(menu_json) and menu_json:
                try:
                    menus = json.loads(menu_json)
                    if isinstance(menus, list):
                        menu_evaluations.extend(menus)
                except:
                    pass

        # ë©”ë‰´ë³„ ì§‘ê³„
        menu_stats = {}
        for menu_eval in menu_evaluations:
            if isinstance(menu_eval, dict):
                menu_name = menu_eval.get('ë©”ë‰´ëª…', '')
                evaluation = menu_eval.get('í‰ê°€', '')

                if menu_name and evaluation:
                    if menu_name not in menu_stats:
                        menu_stats[menu_name] = {'ê¸ì •': 0, 'ë¶€ì •': 0, 'ì¤‘ë¦½': 0}

                    if evaluation in menu_stats[menu_name]:
                        menu_stats[menu_name][evaluation] += 1

        if not menu_stats:
            return pd.DataFrame()

        menu_df = pd.DataFrame(menu_stats).T
        menu_df['ì´_ì–¸ê¸‰'] = menu_df.sum(axis=1)
        menu_df['ê¸ì •_ë¹„ìœ¨'] = (menu_df['ê¸ì •'] / menu_df['ì´_ì–¸ê¸‰'] * 100).round(1)
        menu_df = menu_df.sort_values('ì´_ì–¸ê¸‰', ascending=False)

        return menu_df

    def get_hidden_complaints(self) -> List[str]:
        """ìˆ¨ì€ ë¶ˆë§Œ ì¶”ì¶œ"""
        complaints = self.df['ìˆ¨ì€ë¶ˆë§Œ'].dropna()
        complaints = complaints[complaints != '']
        return complaints.tolist()

    def get_revisit_intent_distribution(self) -> Dict:
        """ì¬ë°©ë¬¸ ì˜ë„ ë¶„í¬"""
        revisit_dist = self.df['ì¬ë°©ë¬¸ì˜ë„'].value_counts()
        return revisit_dist.to_dict()

    def generate_full_report(self) -> str:
        """ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_lines = []
        report_lines.append("=" * 100)
        report_lines.append("ğŸ¯ ë¦¬ë·° ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸")
        report_lines.append("=" * 100)

        # ê¸°ë³¸ í†µê³„
        stats = self.get_basic_stats()
        report_lines.append(f"\nğŸ“Š ë¶„ì„ ê°œìš”")
        report_lines.append(f"  - ì´ ë¦¬ë·° ìˆ˜: {stats['total_reviews']:,}ê±´")

        report_lines.append(f"\nğŸ† ì „ì²´ í‰ê·  ì ìˆ˜")
        for category, score in stats['avg_scores'].items():
            report_lines.append(f"  - {category}: {score:.2f}/5")

        # í‚¤ì›Œë“œ
        keywords = self.extract_keywords()
        report_lines.append(f"\nğŸŸ¢ ì£¼ìš” ê°•ì  (ê¸ì • í‚¤ì›Œë“œ Top 15):")
        for keyword, count in keywords['positive'][:15]:
            report_lines.append(f"  {count}íšŒ - {keyword}")

        report_lines.append(f"\nğŸ”´ ì£¼ìš” ì•½ì  (ë¶€ì • í‚¤ì›Œë“œ Top 15):")
        for keyword, count in keywords['negative'][:15]:
            report_lines.append(f"  {count}íšŒ - {keyword}")

        # ê³ ê° ë‹ˆì¦ˆ
        needs = self.extract_customer_needs()
        report_lines.append(f"\nğŸ’¡ í•µì‹¬ ê³ ê° ë‹ˆì¦ˆ Top 10:")
        for need, count in needs[:10]:
            report_lines.append(f"  {count}íšŒ - {need}")

        # ë©”ë‰´ ë¶„ì„
        menu_df = self.analyze_menus()
        if not menu_df.empty:
            report_lines.append(f"\nğŸ½ï¸  ì¸ê¸° ë©”ë‰´ Top 15:")
            for idx, (menu, row) in enumerate(menu_df.head(15).iterrows(), 1):
                report_lines.append(
                    f"  {idx}. {menu}: {row['ì´_ì–¸ê¸‰']:.0f}íšŒ (ê¸ì • {row['ê¸ì •_ë¹„ìœ¨']:.1f}%)"
                )

        # ìˆ¨ì€ ë¶ˆë§Œ
        complaints = self.get_hidden_complaints()
        report_lines.append(f"\nğŸ” ìˆ¨ì€ ë¶ˆë§Œ")
        report_lines.append(f"  - ë°œê²¬: {len(complaints)}ê±´ ({len(complaints)/len(self.df)*100:.1f}%)")
        if len(complaints) > 0:
            report_lines.append(f"\n  ëŒ€í‘œ ì‚¬ë¡€ 5ê°œ:")
            for idx, complaint in enumerate(complaints[:5], 1):
                report_lines.append(f"  {idx}. {complaint}")

        # ì¬ë°©ë¬¸ ì˜ë„
        revisit_dist = self.get_revisit_intent_distribution()
        report_lines.append(f"\nğŸ”„ ì¬ë°©ë¬¸ ì˜ë„")
        for intent, count in revisit_dist.items():
            report_lines.append(f"  - {intent}: {count}ê±´ ({count/len(self.df)*100:.1f}%)")

        # ì•¡ì…˜ í”Œëœ
        report_lines.append("\n" + "=" * 100)
        report_lines.append("ğŸ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ")
        report_lines.append("=" * 100)

        report_lines.append("\n1ï¸âƒ£ ìµœìš°ì„  ê°œì„  ê³¼ì œ (ë¶€ì • ì–¸ê¸‰ ë¹ˆë„ ê¸°ì¤€)")
        for idx, (issue, count) in enumerate(keywords['negative'][:5], 1):
            impact = "ë†’ìŒ" if count > 20 else "ì¤‘ê°„" if count > 10 else "ë‚®ìŒ"
            report_lines.append(f"  [{idx}] {issue} (ì–¸ê¸‰ {count}íšŒ, ì˜í–¥ë„: {impact})")

        report_lines.append("\n2ï¸âƒ£ ê°•ì  ë©”ë‰´ (ë§ˆì¼€íŒ… ê°•í™” ëŒ€ìƒ)")
        if not menu_df.empty:
            top_rated = menu_df[menu_df['ê¸ì •_ë¹„ìœ¨'] >= 85].sort_values('ì´_ì–¸ê¸‰', ascending=False)
            for menu, row in top_rated.head(5).iterrows():
                report_lines.append(
                    f"  â­ {menu}: ê¸ì • {row['ê¸ì •_ë¹„ìœ¨']:.1f}% (ì–¸ê¸‰ {row['ì´_ì–¸ê¸‰']:.0f}íšŒ)"
                )

        report_lines.append("\n" + "=" * 100)
        report_lines.append("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        report_lines.append("=" * 100)

        return "\n".join(report_lines)

    def save_report(self, filepath: str) -> bool:
        """ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            report = self.generate_full_report()
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
            return True
        except Exception as e:
            logger.error(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
